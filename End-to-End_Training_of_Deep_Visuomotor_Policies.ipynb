{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 論文輪読\n",
    "那須野薫(Kaoru Nasuno)/ 東京大学松尾研究室(Matsuo Lab., the University of Tokyo)\n",
    "\n",
    "## メタ情報\n",
    "タイトル：End-to-End Training of Deep Visuomotor Policies  \n",
    "著者：Sergey Levine, Chelsea Finn, Trevor Darrell, Pieter Abbeel  \n",
    "著者所属：UCB  \n",
    "公開：2015年12月  \n",
    "リンク： [arXiv](http://arxiv.org/abs/1504.00702)  \n",
    "ページ数：34   \n",
    "\n",
    "\n",
    "\n",
    "## Abstract\n",
    "\n",
    "policy searchの方法はロボットの幅広いタスクの制御方策の学習を可能とするが、  \n",
    "policy searchの実応用はしばしば、認識や状態推定や低レベルの制御に手作りの要素を必要とする。  \n",
    "この論文では、  \n",
    "我々は  \n",
    "「認知系と制御系を結合してEnd-t-oEndで学習させることで、それぞれの要素を分けて学習させるより、いい性能を得られるか？」  \n",
    "という問いに答えるつもりである。  \n",
    "この問いに答えるために、  \n",
    "我々は観測された生画像を直接ロボットモータのトルク(回転モーメント)にマッピングする方策を学習するのに利用できる手法を開発する。  \n",
    "その方策は7層92,000パラメタのCNNにより表現され、  \n",
    "partially observed guided policy search methodというpolicy searchを教師あり学習に変換する手法により学習する。  \n",
    "この時、教師情報は単純な起動中心のtrajectory-centric reinforcement learning methodにより与えられる。  \n",
    "我々は、  \n",
    "キャップをボトルに回しながらはめる、  \n",
    "という動作など視覚と制御の緊密な整合性を必要とするような幅広い実世界の操作に対する我々の手法を評価し、  \n",
    "また、\n",
    "既存のpolicy searchの方法とのシミュレーションされた比較も提示する。\n",
    "\n",
    "\n",
    "\n",
    "## 選択理由\n",
    "\n",
    "#### ロボット制御を少ないサンプルでRLにより学習させる手法を紹介している。  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 感想\n",
    "ページ数が多い。。。  \n",
    "ふーん。。。。。\n",
    "\n",
    "## 前知識\n",
    "### Reinforcement Learning\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/Reinforcement_learning#Algorithms_for_control_learning)によると、、、  \n",
    "少なくとも4つの制御学習アルゴリズムがある。\n",
    "- Criterion of optimality\n",
    "- Bruto force\n",
    "- Value function approaches\n",
    "- Direct policy search\n",
    "\n",
    "今回はおそらく、Direct policy searchの話。\n",
    "\n",
    "### ロボット上のDNN\n",
    "ロボット制御のように、実世界の知覚運動方策にDNNを使う場合は、様々な課題がある。  \n",
    "- DNNを十分学習させるだけの操作データが得られない。  \n",
    "- ロボットセンサーからの観測データは系全体の状態を含んでいるとは限らない。例えば、完了状態は画像から類推されるべき。  \n",
    "\n",
    "\n",
    "### Policy search\n",
    "policy $\\pi_\\theta({\\bf u}_t|{\\bf o}_t)$の$\\theta$を最適化すること。  \n",
    "${\\bf u}_t$：時刻$t$の行動。  \n",
    "${\\bf o}_t$：時刻$t$の観測。  カメラ画像やロボットの設定など。  \n",
    "$\\theta$：パラメタ。  \n",
    "\n",
    "\n",
    "\n",
    "### Guided policy search\n",
    "Guided policy searchはpolicy searchを教師あり学習に変換する。  \n",
    "効率的でモデルフリーな軌道最適化手続きを利用することで、訓練データを繰り返し構築している。  \n",
    "\n",
    "### Guided policy search under unknown dynamics\n",
    "特に、報告の手法は、\n",
    "訓練時には系全体の状態が観測できるが、テスト時には一部しか観測できないというものである。  \n",
    "ほとんどのタスクにおいて、  \n",
    "すべての状態を与えるためには、訓練中のそれぞれの試行においてすべてのオブジェクトをいくつかの所定の位置に置いておく必要がある。  \n",
    "テスト時には、学習したCNNの方策は新しい、未知の設定に対応することができ、全体の状態はもう必要ない。  \n",
    "教師あり学習で方策が学習されるため、学習にはSGDのような一般的な手法を利用出来る。  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 内容の目次\n",
    "- Introduction\n",
    "- Related Work\n",
    "- Overview\n",
    "- Partially Observed Guided Policy Search\n",
    "- End-to-End Visuomotor Policies\n",
    "- Experimental Evaluation\n",
    "- Discussion and Future Work\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "<img src='files/img/visuomotor/fig1.png' width=\"900px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Related Work\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Overview\n",
    "<img src='files/img/visuomotor/fig2.png' width=\"900px\"/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
