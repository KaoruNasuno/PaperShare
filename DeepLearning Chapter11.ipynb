{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 11 Practical methodology\n",
    "## メタ情報\n",
    "全部で17ページ。  \n",
    "機械学習、特に、ディープラーニングのモデルを学習させる際の、方針やノウハウがかかれている。  \n",
    "常識的なことも結構書かれている。  \n",
    "\n",
    "## 補足\n",
    "数式がなく、ほぼ翻訳です。  \n",
    "翻訳は翻訳者の主観が多分に含まれておりますので、その点ご注意ください。  \n",
    "\n",
    "\n",
    "## はじめに\n",
    "ディープラーニングの技術を適切に適用する為には、  \n",
    "単にどんなアルゴリズムがあるか、やそれらがどう機能するか  \n",
    "をよく知っているだけでは不十分である。  \n",
    "\n",
    "うまく適用する為には、\n",
    "特定に応用対象に適用すべきアルゴリズムを選択する能力や、  \n",
    "機械学習系:(machine learning system)を改善する為に、  \n",
    "実験を通じて生成されるフィードバックを監視し、それに対応する能力が求められている。  \n",
    "\n",
    "機械学習系の日々の開発の中で実際に分析する際には、  \n",
    "データを追加で集めるか、  \n",
    "モデルの容量を増やすか減らすか、  \n",
    "正則化項を加えるか取り除くか、  \n",
    "モデルの最適化手法を改善するか、  \n",
    "モデルの近似推論(approximation inference)を改善するか、  \n",
    "モデルの実装のデバッグするか、  \n",
    "などを選択する必要がある。  \n",
    "\n",
    "これら全ての作業が実行するのに少なくない時間を要するため、  \n",
    "ただ盲目に推察するのではなく、正しい道筋を選べることが大事である。 \n",
    "\n",
    "この本のほとんどの部分は、さまざまな機械学習モデル、さまざまな学習アルゴリズムや、目的関数を扱っており、  \n",
    "機械学習のエキスパートになるためには幅広い多様な機械学習の技術を知りさまざまな数学に精通していることが、  \n",
    "最も重要な要素だという印象を与えているかもしれないが、  \n",
    "実際には、\n",
    "あまり知られていないアルゴリズムをいい加減に適用するよりは、  \n",
    "一般的なアルゴリズムを適切に適用する方が\n",
    "たいていはうまくいく。  \n",
    "アルゴリズムを正しく適用することはいくつかのかなりシンプルな手続きをマスターできているかどうかに依存している。  \n",
    "このチャプターの多くのオススメ事項はAndrew Ng(Ng, 2015)のレクチャーから引っ張ってきたものである。\n",
    "\n",
    "我々は下記の実践的なひな形のプロセスをお薦めする。  \n",
    "- 目的(ゴール)を決める。どの誤差関数を使うのか、その誤差関数における目的の値は何なのか。  \n",
    "どれくらいの精度がほしいのか。誤差は絶対に0にならない。  \n",
    "科学的な疑問点に答えたいのか、現実世界で一番良い製品を作りたいのか、などの目的に応じて、すべきことは異なる。  \n",
    "データ収集は時間も金も人も必要なので、注意が必要。どれぐらいの精度が欲しいのか、費用対効果を考えるべき。  \n",
    "- できるだけ早く(as soon as possible)、適切な性能評価指標による推定の部分も含めて、end-to-endの動くパイプラインを構築すること。\n",
    "- 性能のボトルネックを見定める為に、系をよく計測すること。どの部分が期待より低い性能で、それがoverfittingなのかunderfittingなのか、データやソフトウェアの問題なのか診断する。  \n",
    "- 新規データの収集、ハイパーパラメタの調整、アルゴリズムの変更など徐々に変化を増やすことを、測定から得られた知見に基づいて、繰り返すこと。\n",
    "\n",
    "データ収集の意思決定はいつすべきか。  \n",
    "データがもっとあれば汎化性能は高まるだろうが、データを収集するコストに比例して改善しない場合もある。  \n",
    "データの増分と性能の増分の関係は実験で、ある程度増えるが、どこかでサチるという仮定のもと予測できる。  \n",
    "注意したいのは、データ全体に比べてちょっとデータ増やしたくらいでは汎化性能に顕著な違いが現れないということで、  \n",
    "ログスケールでデータの量を変えて実験することが望ましい。  \n",
    "\n",
    "このチャプターでは、特に、ハイパーパラメタの選択に関することを取り上げていく。  \n",
    "\n",
    "\n",
    "目次  \n",
    "1. Defalut Baseline Models  \n",
    "2. Selecting Hyperparameters  \n",
    "3. Debugging Strategies  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Default Baseline Models\n",
    "暫定的なベースラインについて。  \n",
    "問題の複雑さに応じて、\n",
    "問題がAi-completeなカテゴリの問題(物体認識、会話認識、機械翻訳など)であれば、適切なディープラーニングのモデルからはじめるのがいいかもしれない。  \n",
    "### データ構造にあわせたモデル選択\n",
    "まず、データ構造にあわせてモデルを選択する。  \n",
    "固定長入力で教師あり学習を行いたいなら、全結合のFFNから始めるのが良い。  \n",
    "トポロジカル構造のあるデータ(画像等)であれば、CNNから始めるのが良い。その際、活性化関数はpiecewise linear unit(Relu, LRelu, PRelu, maxout)がいいだろう。  \n",
    "入力と出力が系列なら、gated recurrent net(LSTMとかGRU)がいいだろう。  \n",
    "\n",
    "### 最適化手法の選択\n",
    "まずは、SGD with momentum with decaying learning rateがいいだろう。   \n",
    "decay rateの設定の仕方はいくつかある。  \n",
    "他には、Adamもいい(これから改良していくから注目しといてー)。  \n",
    "\n",
    "\n",
    "### データサイズにあわせた正則化の考慮\n",
    "数十数百万以上のデータがないなら、はじめからなんらかの正則化を行った方が良いだろう。  \n",
    "Eearly stoppingはほとんどどこでも使われている。  \n",
    "Drop outは実装が簡単で多くのモデルやアルゴリズムに相性がいい素晴らしい正則化手法である。  \n",
    "Batch normalizationも最近一般的に利用されるようになってきた。  \n",
    "\n",
    "### 類似問題はあるか？\n",
    "もし、よく研究された他の類似したタスクがあるなら、そこでうまくいっているアルゴリズムとモデルをコピーして始めるのがいいだろう。  \n",
    "場合によっては、学習済のモデルをコピーしてもいいかもしれない。  \n",
    "例えば、画像解析する時にはImageNetで学習済のCNNの特徴量をつかうのが普通。    \n",
    "\n",
    "### 教師なし学習について\n",
    "よくある質問として、教師なしpretrainingを使うかどうか、というのがあるが、これは、ドメインによる。  \n",
    "例えば、NLPではword embeddingを利用することでかなり精度が上がることが分かっている。  \n",
    "一方で、CVではいまの教師なし学習の技術はあまり恩恵を受けられておらず、  \n",
    "ラベルのついたデータが少ない場合に半教師あり学習が有効であるぐらいである。  \n",
    "教師なし学習が有効だと分かっている領域であれば使えば良いし、そうじゃなければ使う必要はない。  \n",
    "Overfittingするって分かってから使えば良いだけの話。  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Selecting Hyperparameters  \n",
    "hyperperameterの選択はmanually と automaticallyの2つ。  \n",
    "対象を知っているかどうか、計算コストをかけられるかどうかなどがポイント。  \n",
    "\n",
    "### 2.1 Manual Hyperparameter Tuning\n",
    "ハイパーパラメタを手で選択する為には、  \n",
    "各ハイパーパラメタとtrian errorとgeneralization error、計算リソース(メモリや実行時間)の関係を理解している必要がある。  \n",
    "\n",
    "自分でハイパーパラメタを選択することの目的は、  \n",
    "実行時間とメモリ制約に関して最も低い汎化誤差を見つけることである。   \n",
    "エンジニアリングの課題でもあるが、  \n",
    "ここでは、ハイパーパラメタを修正することで汎化誤差を下げる方法に焦点を当てる。   \n",
    "\n",
    "\n",
    "効果的なcapacityは主に下記の3に起因する。  \n",
    "モデルの表現のcapacity、  \n",
    "モデルを学習する為の学習アルゴリズム、  \n",
    "コスト関数と訓練手続きがモデルを正則化できるか、\n",
    "\n",
    "ハイパーパラメタを変えると、モデルのcapacityが増えるのか、減るのかを理解して、  \n",
    "overfittingしているのか、underfittingしているのかを見ながら、調整していく。  \n",
    "多くのハイパーパラメタと汎化誤差の関係はU字カーブになっているので、ちょうどいいところが設定する。  \n",
    "\n",
    "learning rateは一番重要なハイパーパラメタで、もし時間がないのであれば、これを調整するのがいい。  \n",
    "\n",
    "最終的には、汎化誤差を小さくしたい。  \n",
    "訓練誤差が低い限り、データを追加すれば汎化誤差も下がるので、目標の精度が達成されるまでそういったアプローチを続ける方法もある。  \n",
    "計算コストが大きくなるという問題や、最適化があまり上手く行かない場合があるという問題はあるが。  \n",
    "\n",
    "|ハイパーパラメタ |capacityが増える場合 | 理由 | 注意|\n",
    "|:--:|:--:|:--:|:--:|\n",
    "|隠れ層のユニット数| 増 | -  |メモリ、計算時間 |\n",
    "| leanrnig rate| 適切な値 | -  | - |\n",
    "|Convolutional kearnel width | 増  | - |- |\n",
    "|implicit zero padding | 増 | - | メモリ、計算時間 |\n",
    "|weight decay coefficient |減| -  | - |\n",
    "|dropout rate | 減| - | - |\n",
    "\n",
    "\n",
    "### 2.2 Automatic Hyperparameter Optimization Algorithms\n",
    "hyperparameter opitimization algorithmは存在するが、そのアルゴリズムもハイパーパラメタ(幅等)を必要としている。  \n",
    "結果は、利用しない場合よりは安定する傾向にあるらしい。  \n",
    "\n",
    "### 2.3 Grid Search\n",
    "<img src='files/GridSearch.png' width=\"600px\"/>\n",
    "グリッドサーチの場合は、だいたいログスケールにしてハイパーパラメタのグリッドを設定することが多い。  \n",
    "learning rateだったら、$\\{.1, .01, 10^{-3}, 10^{-4}, 10^{-5}\\}$とか、  \n",
    "隠れ層のユニット数だったら、$\\{50, 100, 200, 500, 1000, 2000\\}$とか。  \n",
    "ハイパーパラメタが$m$個あってグリッドがそれぞれ$n$個あったら、\n",
    "計算量が$O(n^m)$のオーダで、  \n",
    "ハイパーパラメタの数とグリッドの数に応じて爆発的に計算量が増えることが、グリッドサーチの欠点。    \n",
    "一応並列処理できるけど、焼け石に水。\n",
    "\n",
    "### 2.4 Random Search\n",
    "グリッドサーチよりもランダムサーチの方が探索が早く収束し、しかもいいところに収束する。  \n",
    "各ハイパーパラメタの周辺分布を定義する。例えばバイナリだったらベルヌーイ分布とか、連続値だったらログスケール一様分布とか。  \n",
    "例えば、leanring rateであれば、下記のようにする。  \n",
    "$$\n",
    "log\\_learning\\_rate \\sim U(-1, -5)  \n",
    "$$  \n",
    "$$\n",
    "learning\\_rate = 10^{log\\_learning\\_rate}\n",
    "$$  \n",
    "隠れ層のユニット数だったら、\n",
    "$$\n",
    "log\\_number\\_of\\_hidden\\_units \\sim U(log(50), log(2000))  \\\\\n",
    "$$  \n",
    "利点は\n",
    "- 実行回数の関数として見なせる最も良いvalidation errorはグリッドサーチよりランダムサーチを用いた場合の方が収束しやすい。  \n",
    "- ランダムサーチを使えば、グリッドサーチとは対照的に、実行が完了しなくても、解釈可能で利用できる結果を得る為に必ずしもリスタートする必要はない。  \n",
    "- もっと実行して細かく探索したかったら、必ずしもscrachから始める必要はない。グリッドサーチとは対照的に実行がi.i.dなので、もっと実行すればより細かく探索したことになる。\n",
    "\n",
    "\n",
    "### 2.5 Model-Based Hyperparameter Optimization\n",
    "ハイパーパラメタの探索はそれ自体が最適化問題と見なせる。  \n",
    "最適化されるべきコストはvalidation set の誤差である。  \n",
    "validation setについて微分可能な誤差関数が与えられているなら、勾配を求めて勾配降下法を使えば良いが、  \n",
    "実際のほとんどの設定では、高い計算とメモリコストが高いということや、ハイパーパラメタが例えば離散値を取るなど微分不能なため、勾配が得られない。  \n",
    "勾配が得られないという問題を補完する為の、\n",
    "ベイジアンハイパーパラメタ最適化というアプローチもあるらしい。  \n",
    "ベイジアン回帰によるvalidation errorのモデルを構築し、各ハイパーパラメタにおけるvalidation errorの期待値と曖昧さを推定する。  \n",
    "この最適化は探索と利用のトレードオフを含む。  \n",
    "\n",
    "\n",
    "現状では、我々は明確にベイジアンハイパーパラメタ最適化は、よりよい深層学習結果や簡単に深層学習結果を得る確立されたツールとして、お薦めすることはできない。  \n",
    "ベイジアンハイパーパラメタ最適化は、たまに人間の専門家を上回ることもあるが、そうでない場合は悲惨である。  \n",
    "\n",
    "ほとんどのハイパーパラメタ最適化アルゴリズムの欠点は訓練実験を完全に実行し終えるまでは、情報を得られないということで、  \n",
    "これは、かなり効率が悪い。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Debugging Strategies \n",
    "機械学習系の性能が芳しくないとき、その原因がアルゴリズムに依るものなのか、それともバグがあるからなのかを見分けるのが難しい。  \n",
    "機械学習系はさまざまな理由でデバッグが難しい。  \n",
    "\n",
    "ほとんどの場合、我々は事前にそのアルゴリズムがどのように対象に対して機能するのかは分かっていない。  \n",
    "適当なデータに対して誤差が5％だったとして、その結果が最適なのか順最適なのかは、それだけでは分からない。  \n",
    "\n",
    "加えて、機械学習のモデルは複数の部分が相互に適応し合うので、一ヶ所が壊れていたとしても、他の部分が適応してまぁまぁいい結果を出してしまうことがある。  \n",
    "例えば、$\\phi(Wx+b)$の$b$項の更新は、実装が間違っていたとしても$W$の更新で相殺されてしまう可能性がある。  \n",
    "\n",
    "デバッグの方針はだいたい2通りしかなくて、  \n",
    "1つは、凄い簡単な問題に対して適用して予想通りの結果が出てくのを確認するか、  \n",
    "もう1つは、部分部分の実装を独立して検証するか  \n",
    "である。  \n",
    "下記にいくつかの方法を取り上げる。  \n",
    "\n",
    "### Visualize the model in action\n",
    "例えば、物体検知のモデルであれば、領域を画像に表示するのがいい。  \n",
    "生成モデルで会話を扱うのであれば、生成されたもの聞いてみるのが良い。  \n",
    "常識ではあるが、例えば、評価指標のバグは致命的だが、そういうのは回避できる。  \n",
    "\n",
    "### Visualize the worst mistakes\n",
    "ほとんどのモデルは何かしら確信度のようなものが得られるが、\n",
    "正しくモデリングすることが最も難しい訓練データを見ることで、  \n",
    "前処理やラベリングの問題を見つけることができるかもしれない。  \n",
    "\n",
    "\n",
    "### Compare train and test error, evaluate if overfitting or underfitting\n",
    "train errorよりtest errorが大きい時はoverfittingしているので、正則化の手法を導入する必要がある。  \n",
    "一方で、train errorもtest errorも大きい時はunderfittingしているので、モデルのcapacityが増えるようにhyperparameterを調整する必要がある。  \n",
    "ちょうどいい塩梅が一番良い。  \n",
    "\n",
    "\n",
    "\n",
    "### Fit a tiny dataset\n",
    "training errorが大きい場合は、underfittingしているか、バグがあるか、であるが、    \n",
    "小さなモデルでも小規模のデータセットに対しては十分フィットすることが保障されているため、  \n",
    "小さなデータセットに適用してみ様子を見るのが良い。  \n",
    "例えば、1つのデータしかない分類問題のデータセットであれば、バイアス項を調整することで、フィットすることができる。  \n",
    "\n",
    "### Compare symbolic derivatives to numerical derivatives\n",
    "勾配の計算を自分で実装しなければならない場合や新しいシンボルの微分処理を追加する場合であれば、  \n",
    "エラーのよくある原因は勾配の表現を正しく実装できていないことである。  \n",
    "※詳細は省略：我々は実装しない。  \n",
    "\n",
    "### Monitor histrograms of activations and gradient\n",
    "大きな人まとまりのデータ(1バッチなど)に対して、活性化と勾配を可視化することは役に立つ場合が多い。  \n",
    "活性化する前の隠れ層のユニットの値から、サチっているのか、どれぐらいの頻度でサチるのか。  \n",
    "例えば、RELUだったら、どれぐらい0になるのか、とか。  \n",
    "tanhだったら活性化まえの絶対値の平均ユニットがどれぐらいサチっているのか分かる。  \n",
    "伝搬する勾配が消滅したり爆発したりする多層NNでは、最適化はうまくいかないかもしれない。  \n",
    "最後に、勾配の大きさとそのパラメタの大きさを比較することは役に立つ。  \n",
    "Bottou2015に示唆されているが、だいたい1回のminibatchの更新でパラメタの1%ぐらい更新されていてほしく、  \n",
    "これは50%でも0.001%でもない。  \n",
    "もし、データがスパースだったら、いくつかのパラメタはほとんど更新されないかもしれない。  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
