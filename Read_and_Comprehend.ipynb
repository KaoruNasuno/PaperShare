{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 論文輪読\n",
    "那須野薫(Kaoru Nasuno)/ 東京大学松尾研究室(Matsuo Lab., the University of Tokyo)\n",
    "\n",
    "## メタ情報\n",
    "タイトル：Teaching Machines to Read and Comprehend   \n",
    "著者所属：Google DeepMind, University of Oxford  \n",
    "公開：2015年6月  \n",
    "リンク： [arXiv](http://arxiv.org/abs/1506.03340)  \n",
    "ページ数：13   \n",
    "\n",
    "\n",
    "\n",
    "## Abstract\n",
    "\n",
    "自然言語文書を読むように機械を学習させることは、捉えどころのない課題である。  \n",
    "機械による読解システムは提示された文書の内容に関する問題への回答能力に基づいて評価されるが、  \n",
    "しかし、これまで、大規模な訓練およびテストデータセットはこの類の評価には用意されていなかった。  \n",
    "この論文では、我々は大規模な教師あり学習用の文書読解データを提供し、このボトルネックを解消する新しい方法論を定義する。  \n",
    "これによって、\n",
    "言語構造に関する最低限の事前知識を用いることで、  \n",
    "実際の文書を読んで難しい問題に回答することを学習するdeep neural networksに基づいたアテンションの類を開発できるようになる。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 選択理由\n",
    "#### DeepMind, Attention, RNNというキーワード\n",
    "\n",
    "#### 自然言語処理の特に、モデルの知識獲得に関する内容\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 感想\n",
    "ふーん、という感じ。  \n",
    "結果に、強い意外感はない。  \n",
    "タイトル読んだ段階でのイメージとやや違った。  \n",
    "Unsupervised でやる方法を提案して欲しかった。  \n",
    "\n",
    "\n",
    "\n",
    "## 目次\n",
    "- Introduction\n",
    "- Supervised training data for reading comprehension\n",
    "- Models\n",
    "- Empirical Evaluation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "bag-of-wordsによる情報検索アルゴリズムから文書読解ができる機械へのみちのりの進展はゆっくりである。  \n",
    "\n",
    "教師あり自然言語読解に利用できるデータを作るのは、難しいことが示されれているが、  \n",
    "some reasearchersは合成物語とクエリの生成を探索する研究している。  \n",
    "\n",
    "本稿では、教師あり学習用の自然言語読解データセットの構築する新しい方法論を導入することで、  \n",
    "現実の自然言語訓練データが不足しているという課題を、我々は直接扱おうとしている。\n",
    "\n",
    "我々は、新しい読解用の深層学習モデルを構築し、新しいコーパスの有効性を示す。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Supervised training data for reading comprehension\n",
    "読解タスクは自然と、教師あり学習問題の定式化となろう。\n",
    "Specifically we seek to estimate the conditional probability p(a|c, q), where c is a context document, q a query relating to that document, and a the answer to that query.\n",
    "特に、$p(a|c, q)$という条件付き確率を推定する問題を解くことになる（qがクエリ(質問)、aが回答、cが文脈つまり文書）。\n",
    "\n",
    "こうしたアプローチは、大規模な訓練用のコーパス（文書-質問-回答のトリプレット）を必要とするが、  \n",
    "これまでそんなコーパスは数百程度の事例に限られており、したがって、ほとんど検証ようにしか使えなかった。\n",
    "\n",
    "ここでは、現実世界の大規模な教師あり学習の読解モデル用の訓練データを構築する方法論を提案する。  \n",
    "CNNの11万記事とDailyMailの22万記事を集めた。  \n",
    "記事の要約がリスト形式で存在するが、それらは記事の抽象であり、抜き出しではないため、この実験に利用できる。    \n",
    "文書-質問-回答のトリプレットを各要約を先行文献の方法に従い、質問文に書き換えることで、構築した。   \n",
    "結果として、1M程度のデータを得た。  \n",
    "\n",
    "\n",
    "<img src='files/img/Read_and_Comprehend01.png' width=\"900px\"/>\n",
    "\n",
    "### 2-1. Qualitative Analysis of Answer Difficulty\n",
    "タスクが難しいってことを言いたい。  \n",
    "\n",
    "人間に解かせた。    \n",
    "Simple：文法や意味的な複雑性がないもの。  \n",
    "Lexical：語彙的な一般化が必要なもの。  \n",
    "Coref：同一指示の解決が必要なもの。  \n",
    "Cref/Lex：Lexcalで、かつ、Corefなもの。  \n",
    "Complex：因果関係処理や、他の複雑な推論が必要なもの。  \n",
    "Unanswerable：回答不能。  \n",
    "\n",
    "30%はComplexで、10%は回答不能だから、めっちゃ難しい。\n",
    "\n",
    "\n",
    "### 2-2. Entity replacement and permutation\n",
    "<img src='files/img/Read_and_Comprehend02.png' width=\"900px\"/>\n",
    "\n",
    "本研究の目的は、読解能力を評価したいのであって、世界知識や単語の共起を評価したいのではない。  \n",
    "例)\n",
    "ハイテクなブラは乳Xを防ぐ  \n",
    "SaccharinはXに効く  \n",
    "魚の脂は前立腺Xに効く  \n",
    "X=ガン  \n",
    "こうした事例は、知識や単語の共起で解けてしまうので、問題として不適。  \n",
    "\n",
    "\n",
    "そうした悪い解決方法に陥らないようにするために、  下記の方法で、匿名化とランダム化をおこなった。\n",
    "1. 単語の同一指示処理  \n",
    "2. 同一単語を同一IDで置き換え、匿名化  \n",
    "3. 文書のロードの度にID名をランダムに変える。  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Models\n",
    "ベースライン2つ、  \n",
    "シンボリックマッチング2つ、  \n",
    "深層学習3つ。\n",
    "\n",
    "### 3-0. ベースライン\n",
    "#### Maximum frequency\n",
    "当該文脈における単語の最大出現頻度をもとに回答。  \n",
    "#### Exclusive frequency\n",
    "当該文脈における単語の最大出現頻度をもとに回答するが、質問文には含まれていないものを回答。  \n",
    "\n",
    "### 3-1. Symbolic Matching Models\n",
    "伝統的には自然言語処理モデルをパイプでつなげて、問題回答が行われていた。  \n",
    "つまり、言語アノテーション、構造化された単語の知識や意味への分解とか。\n",
    "そうした手法をいくつか。\n",
    "#### Frame-semantic Parsing\n",
    "<img src='files/img/Read_and_Comprehend03.png' width=\"900px\"/>\n",
    "「誰が誰に何をしたか」を特定しようという手法。  \n",
    "\n",
    "\n",
    "\n",
    "#### Word Distance Benchmark\n",
    "質問文におけるすべての単語について、もっとも近くに位置する文脈文の単語との距離の足しあわたものをスコアとする。  \n",
    "ちょっと、よく分からない。\n",
    "$$\n",
    "p(a | d, q) \\propto exp(W(a)g(d, q)), s.t. a \\in d,\n",
    "$$\n",
    "ここでは、\n",
    "$W(a)0$は$W$の$a$行目、  \n",
    "関数$g(d, q)$は文書と質問文のペアを表現するベクトルを返す。  \n",
    "\n",
    "where W (a) indexes row a of weight matrix W and through a slight abuse of notation word types double as indexes. Note that we do not privilege entities or variables, the model must learn to differentiate these in the input sequence. The function g(d,q) returns a vector embedding of a document and query pair.\n",
    "\n",
    "\n",
    "### 3-2. Neural Network Models\n",
    "#### The Deep LSTM Reader\n",
    "<img src='files/img/Read_and_Comprehend06.png' width=\"900px\"/>\n",
    "<img src='files/img/Read_and_Comprehend07.png' width=\"600px\"/>\n",
    "2層のLSTM。  \n",
    "数式のまま。  \n",
    "わかり易い。  \n",
    "#### The Attentive Reader\n",
    "<img src='files/img/Read_and_Comprehend04.png' width=\"600px\"/>\n",
    "<img src='files/img/Read_and_Comprehend08.png' width=\"300px\"/>\n",
    "bi-directional LSTMを使った、ただのattentionモデル。  \n",
    "文書(左)の方は、attentionするため、すべての隠れ層を$r$への入力とする。  \n",
    "質問文(右)の方は、各方向の最後の隠れ層を$u$への入力とする。  \n",
    "わかり易い。\n",
    "\n",
    "<img src='files/img/Read_and_Comprehend09.png' width=\"300px\"/>\n",
    "\n",
    "\n",
    "#### The Impatient Reader\n",
    "<img src='files/img/Read_and_Comprehend05.png' width=\"600px\"/>\n",
    "<img src='files/img/Read_and_Comprehend10.png' width=\"600px\"/>\n",
    "<img src='files/img/Read_and_Comprehend11.png' width=\"300px\"/>\n",
    "\n",
    "わかりにくい。  \n",
    "The Attentive Readerをちょっとかえたもの。  \n",
    "質問文の新しい単語が読まれるたびに、文書を読み返している。  \n",
    "$r(i)$が$|q|$分だけある。\n",
    "$r(i)$はrecurrentになっている。\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Empirical Evaluation\n",
    "目的\n",
    "1. 幅広いモデルを適用して、このタスクが難しいということを確立させること。  \n",
    "2. ニューラルモデルとパースベースの手法を比較すること。  \n",
    "3. ニューラルモデルの中で、どの部分が予測に寄与しているのか明らかにすること。特にアテンションが。  \n",
    "\n",
    "\n",
    "<img src='files/img/Read_and_Comprehend12.png' width=\"900px\"/>\n",
    "値はAccuracy。  \n",
    "60%が正しく回答できており、  \n",
    "これは、解けないか、複雑な推論を用いない問題はだいたい回答できていることを意味する。\n",
    "<img src='files/img/Read_and_Comprehend13.png' width=\"900px\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Appendixに、他のattentionの事例あり。)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
